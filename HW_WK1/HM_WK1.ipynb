{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa398616",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "We need to import all the necessary libraries need for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f34fb6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "# from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5846486",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"fhv_tripdata_2021-01.parquet\")\n",
    "df2 = pd.read_parquet(\"fhv_tripdata_2021-02.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a97ec52",
   "metadata": {},
   "source": [
    "## 1. Number of records in Jan 2021 FHV data\n",
    "\n",
    "Here we need to find the rows and columns of the 'df' data defined above which is the Han 2021 FHV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42b949b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1154112, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e254c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "    \n",
    "    df['duration'] = df.dropOff_datetime - df.pickup_datetime # let get the duration of thetrip, this we can get by substracting  the dropoff_time from pick_time\n",
    "    df.duration = df.duration.apply(lambda td:td.total_seconds() / 60) # # convert to seconds\n",
    "    \n",
    "    df = df[((df.duration >= 1) & (df.duration <= 60))]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0c292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = read_dataframe('fhv_tripdata_2021-01.parquet')\n",
    "df_val = read_dataframe('fhv_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28beb12",
   "metadata": {},
   "source": [
    "## 2. Average duration in Jan 2021 FHV\n",
    "\n",
    "To calculate the duration in Jan 2021, i substracted the dropoff from the pickup datatime. The convert it to minutes by dividing the total_second by 60. Thereafter, i used the pandas function mean to find the mean of duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78322db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.247253368247375"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.duration.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb0f262",
   "metadata": {},
   "source": [
    "## 3. Fraction of missing values\n",
    "\n",
    "I found the null values of `PUlocationID` and `DOlocationID` features not withstanding that we have more than two missing features in train_df dataset. For the purpose of this homework, we will work with these two features (`PUlocationID` and `DOlocationID`).\n",
    "\n",
    "To get the missing values i found the sum of the missing values of the categorical variable divided by the len of the categorical variable as defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c922a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PUlocationID    0.835273\n",
       "DOlocationID    0.133270\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = ['PUlocationID', 'DOlocationID']\n",
    "train_df[categorical ].isnull().sum() / len(train_df[categorical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "076e666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PUlocationID', 'DOlocationID']\n",
    "\n",
    "# train_df[categorical ].isnull().sum() / len(train_df[categorical])\n",
    "train_df[categorical] = train_df[categorical].astype(str)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "683ebc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_train = train_df[categorical].to_dict(orient = 'records')\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(dict_train)\n",
    "\n",
    "target = 'duration'\n",
    "y_train = train_df[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b22c783",
   "metadata": {},
   "source": [
    "## 4. Dimensionality after OHE\n",
    "\n",
    "Using DictVectorizer as a feature extraction that uses One hot Encoder, we fit_transform our categorical features in it, saving it in X_train variable. Thereafter, i found shape of the X_train OHE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91ed1cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1109826, 525)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa909b1b",
   "metadata": {},
   "source": [
    "## 5.  RMSE on Train Data\n",
    "\n",
    "I trained the data with LinerRegression, then find the RMSE of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38b02360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.528519107211325"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "x_pred = lr.predict(X_train) # Make prediciton on the train\n",
    "mean_squared_error(y_train, x_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a418716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "la = Lasso(alpha = 0.0001)\n",
    "la.fit(X_train, y_train)\n",
    "\n",
    "x_pred = la.predict(X_train) # Make prediciton on the train\n",
    "mean_squared_error(y_train, x_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1564121a",
   "metadata": {},
   "source": [
    "## 6. RMSE on Validation Data\n",
    "\n",
    "For validation, i used the second `df2` data, which the model have not seen. To test how good the data will behave with data it hasn't seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbf0120",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_train = df_val[categorical].to_dict(orient = 'records')\n",
    "\n",
    "val_df = dv.transform(val_train)\n",
    "\n",
    "target = 'duration'\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7973b1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(val_df) # Make prediciton on the train\n",
    "mean_squared_error(y_val, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28127766",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = la.predict(val_df) # Make prediciton on the train\n",
    "mean_squared_error(y_val, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962904f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb86da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89668780",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('models/lin_reg.bin', 'wb') as f_out:\n",
    "    pickle.dump((dv, lr),f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fdd35e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
